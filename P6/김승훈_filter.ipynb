{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCf2oMCBI4k9"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%tensorflow_version 1.x\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import math\n",
    "import os\n",
    "import errno\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZ-1elJrI4lg"
   },
   "outputs": [],
   "source": [
    "PLOT_DIR = './out/plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9FWvSWZI4ln"
   },
   "outputs": [],
   "source": [
    "def get_grid_dim(x):\n",
    "    \"\"\"\n",
    "    Transforms x into product of two integers\n",
    "    :param x: int\n",
    "    :return: two ints\n",
    "    \"\"\"\n",
    "    factors = prime_powers(x)\n",
    "    if len(factors) % 2 == 0:\n",
    "        i = int(len(factors) / 2)\n",
    "        return factors[i], factors[i - 1]\n",
    "\n",
    "    i = len(factors) // 2\n",
    "    return factors[i], factors[i]\n",
    "\n",
    "\n",
    "def prime_powers(n):\n",
    "    \"\"\"\n",
    "    Compute the factors of a positive integer\n",
    "    Algorithm from https://rosettacode.org/wiki/Factors_of_an_integer#Python\n",
    "    :param n: int\n",
    "    :return: set\n",
    "    \"\"\"\n",
    "    factors = set()\n",
    "    for x in range(1, int(math.sqrt(n)) + 1):\n",
    "        if n % x == 0:\n",
    "            factors.add(int(x))\n",
    "            factors.add(int(n // x))\n",
    "    return sorted(factors)\n",
    "\n",
    "\n",
    "def empty_dir(path):\n",
    "    \"\"\"\n",
    "    Delete all files and folders in a directory\n",
    "    :param path: string, path to directory\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    for the_file in os.listdir(path):\n",
    "        file_path = os.path.join(path, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print ('Warning: {}'.format(e))\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    \"\"\"\n",
    "    Creates a directory\n",
    "    :param path: string\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "def prepare_dir(path, empty=False):\n",
    "    \"\"\"\n",
    "    Creates a directory if it soes not exist\n",
    "    :param path: string, path to desired directory\n",
    "    :param empty: boolean, delete all directory content if it exists\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        create_dir(path)\n",
    "\n",
    "    if empty:\n",
    "        empty_dir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzN_52EVI4lq"
   },
   "outputs": [],
   "source": [
    "def plot_conv_weights(weights, name, channels_all=True):\n",
    "    \"\"\"\n",
    "    Plots convolutional filters\n",
    "    :param weights: numpy array of rank 4\n",
    "    :param name: string, name of convolutional layer\n",
    "    :param channels_all: boolean, optional\n",
    "    :return: nothing, plots are saved on the disk\n",
    "    \"\"\"\n",
    "    # make path to output folder\n",
    "    plot_dir = os.path.join(PLOT_DIR, 'conv_weights')\n",
    "    plot_dir = os.path.join(plot_dir, name)\n",
    "\n",
    "    # create directory if does not exist, otherwise empty it\n",
    "    # utils.prepare_dir(plot_dir, empty=True)\n",
    "    prepare_dir(plot_dir, empty=True)\n",
    "\n",
    "    w_min = np.min(weights)\n",
    "    w_max = np.max(weights)\n",
    "\n",
    "    channels = [0]\n",
    "    # make a list of channels if all are plotted\n",
    "    if channels_all:\n",
    "        channels = range(weights.shape[2])\n",
    "\n",
    "    # get number of convolutional filters\n",
    "    num_filters = weights.shape[3]\n",
    "\n",
    "    # get number of grid rows and columns\n",
    "    grid_r, grid_c = get_grid_dim(num_filters)\n",
    "\n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(min([grid_r, grid_c]),\n",
    "                             max([grid_r, grid_c]))\n",
    "\n",
    "    # iterate channels\n",
    "    for channel in channels:\n",
    "        # iterate filters inside every channel\n",
    "        for l, ax in enumerate(axes.flat):\n",
    "            # get a single filter\n",
    "            img = weights[:, :, channel, l]\n",
    "            # put it on the grid\n",
    "            ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n",
    "            # remove any labels from the axes\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        # save figure\n",
    "        plt.savefig(os.path.join(plot_dir, '{}-{}.png'.format(name, channel)), bbox_inches='tight')\n",
    "\n",
    "\n",
    "def plot_conv_output(conv_img, name):\n",
    "    \"\"\"\n",
    "    Makes plots of results of performing convolution\n",
    "    :param conv_img: numpy array of rank 4\n",
    "    :param name: string, name of convolutional layer\n",
    "    :return: nothing, plots are saved on the disk\n",
    "    \"\"\"\n",
    "    # make path to output folder\n",
    "    plot_dir = os.path.join(PLOT_DIR, 'conv_output')\n",
    "    plot_dir = os.path.join(plot_dir, name)\n",
    "\n",
    "    # create directory if does not exist, otherwise empty it\n",
    "    prepare_dir(plot_dir, empty=True)\n",
    "\n",
    "    w_min = np.min(conv_img)\n",
    "    w_max = np.max(conv_img)\n",
    "c\n",
    "    # get number of convolutional filters\n",
    "    num_filters = conv_img.shape[3]\n",
    "\n",
    "    # get number of grid rows and columns\n",
    "    grid_r, grid_c = get_grid_dim(num_filters)\n",
    "\n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(min([grid_r, grid_c]),\n",
    "                             max([grid_r, grid_c]))\n",
    "\n",
    "    # iterate filters\n",
    "    for l, ax in enumerate(axes.flat):\n",
    "        # get a single image\n",
    "        img = conv_img[0, :, :,  l]\n",
    "        # put it on the grid\n",
    "        ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='bicubic', cmap='Greys')\n",
    "        # remove any labels from the axes\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    # save figure\n",
    "    plt.savefig(os.path.join(plot_dir, '{}.png'.format(name)), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "31V14lEAI4lw",
    "outputId": "63be20b8-32de-4af2-8b86-ebecf321a046"
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n",
    "\n",
    "\n",
    "def conv2d(x_, filter_size, filter_num, stride=1):\n",
    "    \"\"\"\n",
    "    Wrapper of a convolutional layer\n",
    "    :param x_: tensor, input to convolutional layer\n",
    "    :param filter_size: int, size of a convolutional kernel\n",
    "    :param filter_num: int, number of convolutional kernels\n",
    "    :param stride: int, optional, stride\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    # get number of channels in input\n",
    "    channels = x_.get_shape()[3].value\n",
    "\n",
    "    # create weights tensor\n",
    "    weights = tf.Variable(tf.random_normal([filter_size, filter_size, channels, filter_num]))\n",
    "\n",
    "    # add weights tensor to collection\n",
    "    tf.add_to_collection('conv_weights', weights)\n",
    "\n",
    "    # create bias tensor\n",
    "    bias = tf.Variable(tf.random_normal([filter_num]))\n",
    "\n",
    "    # apply weights and biases\n",
    "    preactivations = tf.nn.conv2d(x_, weights, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    preactivations = tf.nn.bias_add(preactivations, bias)\n",
    "\n",
    "    # apply activation function, this is layer output\n",
    "    activations = tf.nn.relu(preactivations)\n",
    "\n",
    "    # add output to collection\n",
    "    tf.add_to_collection('conv_output', activations)\n",
    "\n",
    "    return activations\n",
    "\n",
    "\n",
    "def fc(x_, nodes, keep_prob_=1, act=tf.nn.relu):\n",
    "    \"\"\"\n",
    "    Wrapper for fully-connected layer\n",
    "    :param x_: tensor, input to fully-connected alyer\n",
    "    :param nodes: int, number of nodes in layer\n",
    "    :param keep_prob_: float, optional, keep probability for dropout operation\n",
    "    :param act: tf.nn method, optional, activation function\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    shape = x_.get_shape()\n",
    "\n",
    "    # if rank of input tensor is greater than 2\n",
    "    # we need to reshape it\n",
    "    if shape.ndims > 2:\n",
    "        n = 1\n",
    "        for s in shape[1:]:\n",
    "            n *= s.value\n",
    "        x_ = tf.reshape(x_, tf.stack([-1, n]))\n",
    "        x_.set_shape([None, n])\n",
    "\n",
    "    # get number of column in input tensor\n",
    "    n = x_.get_shape()[1].value\n",
    "\n",
    "    # create weights\n",
    "    weights = tf.Variable(tf.random_normal([n, nodes]))\n",
    "\n",
    "    # create biases\n",
    "    bias = tf.Variable(tf.random_normal([nodes]))\n",
    "\n",
    "    # apply weights and bias\n",
    "    preactivate = tf.add(tf.matmul(x_, weights), bias)\n",
    "    out = preactivate\n",
    "\n",
    "    # apply activation function if not None\n",
    "    if act is not None:\n",
    "        out = act(preactivate)\n",
    "\n",
    "    # apply dropout\n",
    "    out = tf.nn.dropout(out, keep_prob_)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def maxpool(x_, size, stride):\n",
    "    \"\"\"\n",
    "    Wrapper for max-pooling layer\n",
    "    :param x_: tensor, input to max-pooling layer\n",
    "    :param size: int\n",
    "    :param stride: int\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x_,\n",
    "                          ksize=[1, size, size, 1],\n",
    "                          strides=[1, stride, stride, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "# Reshape inputs\n",
    "x_reshaped = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "# First convolutional layer\n",
    "predictions = conv2d(x_reshaped, filter_size=5, filter_num=32)\n",
    "\n",
    "# First max-pooling layer\n",
    "predictions = maxpool(predictions, 2, 2)\n",
    "\n",
    "# Second convolutional layer\n",
    "predictions = conv2d(predictions, filter_size=5, filter_num=64)\n",
    "\n",
    "# Second max-pooling layer\n",
    "predictions = maxpool(predictions, 2, 2)\n",
    "\n",
    "# First fully-connected layer\n",
    "predictions = fc(predictions, 1024, keep_prob)\n",
    "\n",
    "# Output layer, no activation function\n",
    "# This layer returns logits\n",
    "predictions = fc(predictions, n_classes, keep_prob, act=None)\n",
    "\n",
    "# Define loss operation\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predictions, y))\n",
    "val = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = predictions) \n",
    "cost = tf.reduce_mean(val)\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Define accuracy operation\n",
    "correct_predictions = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "U5-X2WAVI4lz",
    "outputId": "3dd74379-d51f-4b8f-82fd-d559a05cf28b"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                   keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y,\n",
    "                                                          keep_prob: 1.})\n",
    "            print(\"\\rIter \" + str(step*batch_size) + \", Minibatch Loss= \" +\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" +\n",
    "              \"{:.5f}\".format(acc), end='')\n",
    "        step += 1\n",
    "    print(\"\\rOptimization Finished!\")\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\",\n",
    "    sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                y: mnist.test.labels[:256],\n",
    "                                keep_prob: 1.}))\n",
    "    # no need for feed dictionary here\n",
    "    conv_weights = sess.run([tf.get_collection('conv_weights')])\n",
    "    conv_out = sess.run([tf.get_collection('conv_output')], feed_dict={x: mnist.test.images[:1]})\n",
    "    print(\"conv_weights & conv_out done!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "lim6jPpHI4l0",
    "outputId": "e9053ae4-b56e-47df-b5b5-1a9d8f5868e0"
   },
   "outputs": [],
   "source": [
    "  # get weights of all convolutional layers\n",
    "  # no need for feed dictionary here \n",
    "  for i, c in enumerate(conv_weights[0]):\n",
    "        plot_conv_weights(c, 'conv{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "PPBut-HsS6KU",
    "outputId": "5e2ab874-5242-4dd3-94f6-ccec4c1b6d3d"
   },
   "outputs": [],
   "source": [
    " # get output of all convolutional layers\n",
    " # here we need to provide an input imag   \n",
    "   for i, c in enumerate(conv_out[0]): \n",
    "        plot_conv_output(c, 'conv{}'.format(i))\n",
    "#        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "239iF48xe7xw",
    "outputId": "9a2ad7b6-e5bb-4b4d-b190-b60c4a4499e6"
   },
   "outputs": [],
   "source": [
    "#!ls -lR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlnB98l0I4l3"
   },
   "outputs": [],
   "source": [
    "  # print(conv_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "52ZV9c5AI4l6"
   },
   "outputs": [],
   "source": [
    "#    print(conv_out[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST CNN filter visualization copy 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
